{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation\n",
    "\n",
    "this notebook uses code from the playground notebook as well as from the Models folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make imports work\n",
    "import os\n",
    "os.chdir('/Users/csuftitan/Desktop/NaiveBayesClassifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models import self_built_model\n",
    "from Models import deep_learning_model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    \"model_NB_1\" : self_built_model.SelfBuiltNB_V1(),\n",
    "    \"model_NB_2\" : self_built_model.SelfBuiltNB_V2(),\n",
    "    \"model_DL\"   : deep_learning_model.KerasModel(),\n",
    "    \"model_MultiNB_sklearn\" : MultinomialNB()\n",
    "    #add more models here\n",
    "}\n",
    "\n",
    "#see how this preset is used in evaluation_dict below\n",
    "eval_preset= {\n",
    "    \"accuracy\": 0,\n",
    "    \"f1_score\": 0,\n",
    "    \"confusion_matrix\": 0,\n",
    "    \"precision\": 0,\n",
    "    \"recall\":0\n",
    "}\n",
    "\n",
    "#holds the evaluation results for each model\n",
    "evaluation_dict = {\n",
    "    \"model_NB_1\" : eval_preset,\n",
    "    \"model_NB_2\" : eval_preset,\n",
    "    \"model_DL\"   : eval_preset,\n",
    "    \"model_MultiNB_sklearn\" : eval_preset\n",
    "    #add more models here\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Data/Preprocessing/data_cooked.csv\")\n",
    "data = data.dropna(subset=['Message']).reset_index(drop=True) #without this I get an error for missing values in training data (wonder why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating MultinomialNB from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['Message'], data['Category'], test_size=0.3, random_state=42)\n",
    "\n",
    "#using a pipeline can connect multiple steps:\n",
    "pipeline = make_pipeline(\n",
    "    CountVectorizer(),  # creates a matrix with word counts\n",
    "    model_dict[\"model_MultiNB_sklearn\"]  # the classifier from scikit\n",
    ")\n",
    "\n",
    "pipeline.fit(X=X_train, y=y_train)\n",
    "\n",
    "#make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "#test and evaluation\n",
    "evaluation_dict['model_MultiNB_sklearn'][\"confusion_matrix\"] = confusion_matrix(y_test, y_pred)\n",
    "evaluation_dict['model_MultiNB_sklearn'][\"f1_score\"] = f1_score(y_test, y_pred)\n",
    "evaluation_dict['model_MultiNB_sklearn'][\"precision\"] = precision_score(y_test, y_pred)\n",
    "evaluation_dict['model_MultiNB_sklearn'][\"recall\"] = recall_score(y_test, y_pred)\n",
    "evaluation_dict['model_MultiNB_sklearn'][\"accuracy\"] = accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Self Built Model 1\n",
    "\n",
    "*WARNING*: Takes about 7:30 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMessage\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m'\u001b[39m], test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m model_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_NB_1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#make predictions\u001b[39;00m\n\u001b[1;32m      7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/Desktop/NaiveBayesClassifier/Models/self_built_model.py:12\u001b[0m, in \u001b[0;36mSelfBuiltNB_V1.fit\u001b[0;34m(self, mails, labels)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, mails, labels):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprior_probas \u001b[38;5;241m=\u001b[39m  NB_Utils\u001b[38;5;241m.\u001b[39mget_prior_probas(labels)\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconditional_probas \u001b[38;5;241m=\u001b[39m \u001b[43mNB_Utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_cond_probas_attempt_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp_mails\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmails\u001b[49m\u001b[43m,\u001b[49m\u001b[43mp_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/NaiveBayesClassifier/Models/self_built_model.py:112\u001b[0m, in \u001b[0;36mNB_Utils.get_cond_probas_attempt_1\u001b[0;34m(p_mails, p_labels)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_index \u001b[38;5;129;01min\u001b[39;00m not_spam_rows_indices:\n\u001b[1;32m    111\u001b[0m     word_count \u001b[38;5;241m=\u001b[39m word_count_matrix[row_index][word_idx]\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(\u001b[43mword_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m): \u001b[38;5;66;03m#only checks if the word appears, not how often\u001b[39;00m\n\u001b[1;32m    113\u001b[0m         word_proba_array[\u001b[38;5;241m1\u001b[39m][word_idx] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (not_spam_count_total)\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;66;03m#-> same as before but for spam=no mails\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Message'], data['Category'], test_size=0.3, random_state=42)\n",
    "\n",
    "model = model_dict[\"model_NB_1\"]\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#test and evaluation\n",
    "evaluation_dict['model_NB_1'][\"confusion_matrix\"] = confusion_matrix(y_test, y_pred)\n",
    "evaluation_dict['model_NB_1'][\"f1_score\"] = f1_score(y_test, y_pred)\n",
    "evaluation_dict['model_NB_1'][\"precision\"] = precision_score(y_test, y_pred)\n",
    "evaluation_dict['model_NB_1'][\"recall\"] = recall_score(y_test, y_pred)\n",
    "evaluation_dict['model_NB_1'][\"accuracy\"] = accuracy_score(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Self Built Model 2\n",
    "\n",
    "*WARNING*: Takes about 7:30 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['Message'], data['Category'], test_size=0.3, random_state=42)\n",
    "\n",
    "model = model_dict[\"model_NB_2\"]\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#test and evaluation\n",
    "evaluation_dict['model_NB_2'][\"confusion_matrix\"] = confusion_matrix(y_test, y_pred)\n",
    "evaluation_dict['model_NB_2'][\"f1_score\"] = f1_score(y_test, y_pred)\n",
    "evaluation_dict['model_NB_2'][\"precision\"] = precision_score(y_test, y_pred)\n",
    "evaluation_dict['model_NB_2'][\"recall\"] = recall_score(y_test, y_pred)\n",
    "evaluation_dict['model_NB_2'][\"accuracy\"] = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Keras DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X,y , test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m model_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_DL\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#make predictions\u001b[39;00m\n\u001b[1;32m     11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/Desktop/NaiveBayesClassifier/Models/deep_learning_model.py:13\u001b[0m, in \u001b[0;36mKerasModel.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m     12\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CountVectorizer()\n\u001b[0;32m---> 13\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtoarray()  \u001b[38;5;66;03m# make it a matrix, the network can handle (not sparse matrix)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m#this will tell how the input shape of the network needs to look like\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m#print(len(cv.get_feature_names()))\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/spam_classifier_env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:1202\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1199\u001b[0m min_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_df\n\u001b[1;32m   1200\u001b[0m max_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features\n\u001b[0;32m-> 1202\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1206\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/spam_classifier_env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:1114\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1113\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1114\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1115\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1116\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/spam_classifier_env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:104\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m         doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/spam_classifier_env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:69\u001b[0m, in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03mapply to a document.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    preprocessed string\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[0;32m---> 69\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accent_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     doc \u001b[38;5;241m=\u001b[39m accent_function(doc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "X = data['Message'] # make it a matrix, the network can handle (not sparse matrix)\n",
    "y = data['Category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y , test_size=0.3, random_state=42)\n",
    "\n",
    "model = model_dict[\"model_DL\"]\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#test and evaluation\n",
    "evaluation_dict['model_DL'][\"confusion_matrix\"] = confusion_matrix(y_test, y_pred)\n",
    "evaluation_dict['model_DL'][\"f1_score\"] = f1_score(y_test, y_pred)\n",
    "evaluation_dict['model_DL'][\"precision\"] = precision_score(y_test, y_pred)\n",
    "evaluation_dict['model_DL'][\"recall\"] = recall_score(y_test, y_pred)\n",
    "evaluation_dict['model_DL'][\"accuracy\"] = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "metrics = ['accuracy', 'f1_score', 'precision', 'recall']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, metric in zip(axes, metrics):\n",
    "    values = [evaluation_dict[model][metric] for model in evaluation_dict]\n",
    "    ax.bar(evaluation_dict.keys(), values, color=['blue', 'green', 'red', 'purple'])\n",
    "    ax.set_title(f'{metric.capitalize()} Comparison')\n",
    "    ax.set_ylabel(metric.capitalize())\n",
    "    ax.set_ylim(0.8, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Plotten der Confusion Matrices\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, (model_name, data) in zip(axes, evaluation_dict.items()):\n",
    "    ConfusionMatrixDisplay(data['confusion_matrix'], display_labels=['Class 0', 'Class 1']).plot(cmap='Blues', ax=ax)\n",
    "    ax.set_title(f'Confusion Matrix for {model_name}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spam_classifier_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
