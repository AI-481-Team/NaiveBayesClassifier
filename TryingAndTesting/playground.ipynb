{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some trying and exploring of possibilities here...\n",
    "\n",
    "this CountVectorizer is quite useful. It counts the words and represents\n",
    "\n",
    "- each sentence / email as a row\n",
    "- each word / term as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'blue', 'green', 'house', 'window']\n",
      "[[1 2 0 1 1]\n",
      " [0 0 1 1 2]\n",
      " [1 2 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts = [\"blue house and blue window\", \"window window green house\", \"green house and blue blue\"]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "term_count_matrix = vectorizer.fit_transform(texts)\n",
    "\n",
    "# The unique words / column names\n",
    "print(vectorizer.get_feature_names()) #in our sklearn version it is get_feature_names, in newer versions it's get_feature_names_out\n",
    "\n",
    "# Each word\"s amount of occurences in texts\n",
    "print(term_count_matrix.toarray())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looking at our data in data_cooked.csv which looks something like this (example)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "urgent contact last weekend draw show prize call claim code valid,1\n",
    "\n",
    "get dump heap mom decid come low bore,0\n",
    "\n",
    "ok lor soni ericsson salesman ask shuhui say quit gd use consid,0\n",
    "\n",
    "privat account statement show un redeem point call identifi code expir,1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count Matrix looks like this:\n",
      " [[0 1 1 1 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 1 0]\n",
      " [0 1 0 1 1 0 1 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "#First get the data\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#I took this from our prepared data and adjusted a bit to illustrate better\n",
    "data= np.array([\n",
    "(\"free claim call code\", 1),\n",
    "(\"heap mom bore\",0),\n",
    "(\"ok salesman quit\",0),\n",
    "(\"urgent call free identifi code\",1)\n",
    "])\n",
    "\n",
    "mails = data[:,0] #all rows, 0th column\n",
    "labels = data[:,1] #all rows, 1st column\n",
    "\n",
    "\n",
    "# Second: use the vectorizer on the mails\n",
    "vectorizer = CountVectorizer()\n",
    "word_count_matrix = vectorizer.fit_transform(mails)\n",
    "print('Word Count Matrix looks like this:\\n', word_count_matrix.toarray())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as a next step, we can calculating:\n",
    "\n",
    "for each word (meaning for each column): Count how often the word appears in a spam sentence and then calculate its probability as \n",
    "\n",
    "Occurences in Spam Mails  /  Amount all mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bore': 0.25,\n",
       " 'call': 0.5,\n",
       " 'claim': 0.25,\n",
       " 'code': 0.5,\n",
       " 'free': 0.5,\n",
       " 'heap': 0.25,\n",
       " 'identifi': 0.25,\n",
       " 'mom': 0.25,\n",
       " 'ok': 0.25,\n",
       " 'quit': 0.25,\n",
       " 'salesman': 0.25,\n",
       " 'urgent': 0.25}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = {}\n",
    "\n",
    "\n",
    "number_all_mails = len(word_count_matrix.toarray())\n",
    "for index,word in enumerate(vectorizer.get_feature_names()):\n",
    "    column = word_count_matrix[:,index]\n",
    "    count = np.count_nonzero(column[column>0]) # column[column>0] makes column a 1D array of True and False values \n",
    "    probabilities[word] = count / number_all_mails\n",
    "\n",
    "probabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how words like call, code, free are rated higher than other words\n",
    "\n",
    "it's still very simple the way it is but could be a start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spam_classifier_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
