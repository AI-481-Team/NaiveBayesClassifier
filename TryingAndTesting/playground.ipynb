{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'blue', 'green', 'house', 'window']\n",
      "[[1 2 0 1 1]\n",
      " [0 0 1 1 2]\n",
      " [1 2 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts = [\"blue house and blue window\", \"window window green house\", \"green house and blue blue\"]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "term_count_matrix = vectorizer.fit_transform(texts)\n",
    "\n",
    "# The unique words / column names\n",
    "print(vectorizer.get_feature_names()) #in our sklearn version it is get_feature_names, in newer versions it's get_feature_names_out\n",
    "\n",
    "# Each word\"s amount of occurences in texts\n",
    "print(term_count_matrix.toarray())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looking at our data in data_cooked.csv which looks something like this (example)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "urgent contact last weekend draw show prize call claim code valid,1\n",
    "\n",
    "get dump heap mom decid come low bore,0\n",
    "\n",
    "ok lor soni ericsson salesman ask shuhui say quit gd use consid,0\n",
    "\n",
    "privat account statement show un redeem point call identifi code expir,1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count Matrix looks like this:\n",
      " [[0 1 1 1 1 3 0 0 0 0 0 0 2]\n",
      " [1 0 0 0 0 0 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 1 1 0]\n",
      " [0 2 0 1 1 2 0 1 0 0 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "#First get the data\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#I took this from our prepared data and adjusted a bit to illustrate better\n",
    "data= np.array([\n",
    "(\"urgent free call expir urgent free claim free code\", 1),\n",
    "(\"heap mom bore\",0),\n",
    "(\"ok salesman quit\",0),\n",
    "(\"urgent call free identifi call free code expir urgent\",1)\n",
    "])\n",
    "\n",
    "mails = data[:,0] #all rows, 0th column\n",
    "labels = data[:,1] #all rows, 1st column\n",
    "\n",
    "\n",
    "# Second: use the vectorizer on the mails\n",
    "vectorizer = CountVectorizer()\n",
    "word_count_matrix = vectorizer.fit_transform(mails)\n",
    "print('Word Count Matrix looks like this:\\n', word_count_matrix.toarray())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as a next step, we can start calculating:\n",
    "\n",
    "for each word (meaning for each column): Count how often the word appears in a spam sentence and then calculate its probability as \n",
    "\n",
    "Occurences in Spam Mails  /  Amount all mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = {}\n",
    "\n",
    "for index,word in enumerate(vectorizer.get_feature_names()):\n",
    "    word_count_matrix[index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spam_classifier_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
